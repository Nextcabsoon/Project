from flask import Flask, render_template, request, jsonify
from urllib.parse import urlparse
import re
import csv
import os
from collections import defaultdict

app = Flask(__name__)   

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
SAFE_DOMAINS_SET = set()
# –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–∞–ø–∫–∏ sait)
# CSV –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CSV_FILE = os.path.join(BASE_DIR, 'final_15million.csv')

def load_safe_domains():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–æ–º–µ–Ω—ã –∏–∑ CSV —Ñ–∞–π–ª–∞"""
    global SAFE_DOMAINS_SET
    if not SAFE_DOMAINS_SET:
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤...")
        try:
            count = 0
            with open(CSV_FILE, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    domain = row.get('domain', '').strip().lower()
                    label = row.get('label', '').strip().lower()
                    if domain and label == 'benign':
                        # –í –±–∞–∑–µ –¥–æ–º–µ–Ω—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –ë–ï–ó TLD (–Ω–∞–ø—Ä–∏–º–µ—Ä, "google", –∞ –Ω–µ "google.com")
                        SAFE_DOMAINS_SET.add(domain)
                        count += 1
                        if count % 100000 == 0:
                            print(f"  –ó–∞–≥—Ä—É–∂–µ–Ω–æ {count} –¥–æ–º–µ–Ω–æ–≤...")
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(SAFE_DOMAINS_SET)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
            print("  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤")
            # Fallback —Å–ø–∏—Å–æ–∫ (–ë–ï–ó TLD, –∫–∞–∫ –≤ –±–∞–∑–µ)
            SAFE_DOMAINS_SET = {'google', 'youtube', 'facebook', 'twitter', 
                               'instagram', 'github', 'stackoverflow', 'wikipedia',
                               'microsoft', 'apple', 'yandex', 'mail', 'vk'}
    return SAFE_DOMAINS_SET

# –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
load_safe_domains()

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
SUSPICIOUS_PATTERNS = [
    (r'bit\.ly|tinyurl\.com|t\.co|goo\.gl|short\.link|ow\.ly|buff\.ly', '–°–µ—Ä–≤–∏—Å —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫'),
    (r'paypal.*\.ru|amazon.*\.ru|facebook.*\.ru|google.*\.ru|microsoft.*\.ru', '–ü–æ–¥–¥–µ–ª—å–Ω—ã–π –¥–æ–º–µ–Ω –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞ —Å .ru'),
    (r'[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+', '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ IP-–∞–¥—Ä–µ—Å–∞ –≤–º–µ—Å—Ç–æ –¥–æ–º–µ–Ω–∞'),
    (r'[a-z0-9-]+\.(tk|ml|ga|cf|gq|xyz|top)', '–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –¥–æ–º–µ–Ω –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è'),
    (r'(secure|verify|account|update|confirm|login|signin).*\.(tk|ml|ga|cf)', '–§–∏—à–∏–Ω–≥–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –¥–æ–º–µ–Ω–µ'),
    (r'[a-z0-9]{20,}\.[a-z]{2,}', '–û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Å–ª—É—á–∞–π–Ω—ã–π –¥–æ–º–µ–Ω'),
    (r'[0-9]{4,}\.[a-z]', '–î–æ–º–µ–Ω –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ü–∏—Ñ—Ä'),
]

# –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–∏—à–∏–Ω–≥–æ–≤—ã—Ö –¥–æ–º–µ–Ω–æ–≤ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
SUSPICIOUS_TLDS = ['tk', 'ml', 'ga', 'cf', 'gq', 'xyz', 'top', 'club', 'click', 'download']

# –°–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–∏—Å–æ–≤ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫
URL_SHORTENERS = ['bit.ly', 'tinyurl.com', 't.co', 'goo.gl', 'short.link', 'ow.ly', 'buff.ly',
                  'is.gd', 'v.gd', 'rebrand.ly', 'cutt.ly', 'shorturl.at', 'tiny.cc']

def extract_domain_without_tld(domain):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –ë–ï–ó TLD –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
    –ù–∞–ø—Ä–∏–º–µ—Ä: google.com -> google, mail.google.com -> google, yandex.ru -> yandex
    """
    # –£–±–∏—Ä–∞–µ–º –ø–æ—Ä—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
    domain = domain.split(':')[0]
    
    parts = domain.split('.')
    if len(parts) >= 2:
        # –ë–µ—Ä–µ–º –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å (–¥–æ–º–µ–Ω –±–µ–∑ TLD –∏ –ø–æ–¥–¥–æ–º–µ–Ω–∞)
        # –ù–∞–ø—Ä–∏–º–µ—Ä: mail.google.com -> google, google.com -> google
        return parts[-2]
    elif len(parts) == 1:
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ —á–∞—Å—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ—ë (—É–∂–µ –±–µ–∑ TLD)
        return parts[0]
    return domain

def check_url_safety(url):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ URL –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"""
    original_url = url
    if not url or not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        domain_without_tld = extract_domain_without_tld(domain)
        path = parsed.path.lower()
        query = parsed.query.lower()
        
        results = {
            'url': url,
            'domain': domain,
            'base_domain': domain_without_tld,
            'is_safe': True,
            'warnings': [],
            'checks': {},
            'risk_score': 0,
            'recommendations': []
        }
        
        risk_score = 0
        
